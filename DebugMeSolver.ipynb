{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f218a4d4",
   "metadata": {},
   "source": [
    "# Debug Me Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6da2be",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f375ce88",
   "metadata": {},
   "source": [
    "### Debug Me File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba7a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./debugme_unpacked', 'rb') as f:\n",
    "    debugme = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fecbe8a",
   "metadata": {},
   "source": [
    "The binary addresses start at `0x400000` so we need this as an offset. As for our search space, it makes sense to avoid the plaintext strings, and null-byte strings: these will XOR together to produce the original plaintext string anyway. Looking through the .data section listing in Ghidra we can see another high-entropy section of scrambled strings start at `0x0055c1c0` and end at `0x0055c470`, so let's search there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4876777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0x400000\n",
    "start_addr = 0x0055c1c0\n",
    "end_addr = 0x0055c470\n",
    "\n",
    "start = start_addr - offset\n",
    "end = end_addr - offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a3c9ed",
   "metadata": {},
   "source": [
    "### Decrypted Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a95f829",
   "metadata": {},
   "source": [
    "During my original searching I used a wordlist and a trie, similar to my approach to the ENIGMA challenge, so search for strings, but it turned out to not be necessary: common ASCII is all you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38476db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validset = set([ord(c) for c in \"!@#$%^&*-_+=(){}[]<>,.?/:;' \"])\n",
    "validset |= set([ord('a')+c for c in range(26)])\n",
    "validset |= set([ord('A')+c for c in range(26)])\n",
    "validset |= set([ord('0')+c for c in range(10)])\n",
    "validset.add(0) # include null-termination of strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3eea15",
   "metadata": {},
   "source": [
    "## String Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa17ecb0",
   "metadata": {},
   "source": [
    "### Pairwise-XOR Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ffbb33",
   "metadata": {},
   "source": [
    "We'll search for all pairs of addresses in our search space, and build the longest common ASCII string possibly by XORing them. Any strings that meet a given threshold in length we'll print for us to read through and analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12cf367",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 8\n",
    "\n",
    "for istart in range(start,end):\n",
    "    for jstart in range(istart,end):\n",
    "        decoded = ''\n",
    "        for ik in range(end-jstart):\n",
    "            c = debugme[istart+ik] ^ debugme[jstart+ik]\n",
    "            if c not in validset:\n",
    "                break\n",
    "            decoded += chr(c)\n",
    "        score = len(decoded)\n",
    "        if score >= threshold:\n",
    "            print(f\"{hex(istart+offset)}-{hex(istart+offset+score)} {hex(jstart+offset)}-{hex(jstart+offset+score)} {jstart-istart} {score}: {decoded}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72946a4a",
   "metadata": {},
   "source": [
    "What do we see here? Fragments of plaintext strings, but not full sentences. However between the different strings we notice that some share an address. Together this implies there must be a single XOR key, but that it is not completely contiguous within the memory: some form of scrambling obfuscation is happening.\n",
    "\n",
    "If we read carefully we'll see what looks like the plaintext strings we already have seen from running the executable, and are present in plaintext. But there are at different addresses.\n",
    "\n",
    "- `0x55c244`-`0x55c250` `0x55c304`-`0x55c310` `192` `12`: `\"s it and I'l\"`\n",
    "- `0x55c1d1`-`0x55c1e0` `0x55c251`-`0x55c260` `128` `15`: `\" give up my sec\"`\n",
    "\n",
    "Looking at the address ranges, `0x55c244`-`0x55c250` and `0x55c251`-`0x55c260` are contiguous too.\n",
    "\n",
    "What if we searched for all the known strings, looking for a common XOR key?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8217df1a",
   "metadata": {},
   "source": [
    "### Pairwise-XOR vs Known-String Hits Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cade8119",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetStrings = [\n",
    "    \"I'm thinking of a number between 1 and 3000000.\",\n",
    "    \"Guess it and I'll give up my secrets.\",\n",
    "    \"I don't think you understand how numbers work...\",\n",
    "    \"Nope! Next time, try concentrating harder.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fe8751",
   "metadata": {},
   "source": [
    "We can perform the same search as before, but this time when we find a decrypted string above the threshold we can also check for it being within the target strings. We shall keep our best alignments and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70849cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import difflib\n",
    "\n",
    "threshold = 8\n",
    "\n",
    "hits = Counter()\n",
    "targetHits = [(0,)]*len(targetStrings)\n",
    "\n",
    "for istart in range(start,end):\n",
    "    for jstart in range(istart+1,end):\n",
    "        decoded = ''\n",
    "        for ik in range(end-jstart):\n",
    "            c = debugme[istart+ik] ^ debugme[jstart+ik]\n",
    "            if c not in validset:\n",
    "                break\n",
    "            decoded += chr(c)\n",
    "        score = len(decoded)\n",
    "        if score >= threshold:\n",
    "            hits[istart] += 1\n",
    "            hits[jstart] += 1\n",
    "            for itarget,targetString in enumerate(targetStrings):\n",
    "                seq = difflib.SequenceMatcher(None, decoded, targetString)\n",
    "                seqMatch = seq.find_longest_match(0, len(decoded), 0, len(targetString))\n",
    "                if seqMatch.size > targetHits[itarget][0]:\n",
    "                    targetHits[itarget] = (seqMatch.size, seqMatch, istart+seqMatch.a,jstart+seqMatch.a, decoded[seqMatch.a:])\n",
    "\n",
    "targetHits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc5dc8b",
   "metadata": {},
   "source": [
    "The results are very insightful: all the top alignments for each target string are exactly 15 characters long, but even more interesting is they all share the same starting location in the target string, and share 1 address. This confirms a single XOR key, and gives us the ability to calculate where the start of our target strings should be in memory, assuming they are contiguous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9912083",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetStarts = [istart-seqMatch.b if hits[istart] == 1 else jstart-seqMatch.b for l,seqMatch,istart,jstart,decoded in targetHits]\n",
    "for tstart, tstring in zip(targetStarts,targetStrings):\n",
    "    print(f\"{hex(tstart+offset)}: {tstring}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a726dbe",
   "metadata": {},
   "source": [
    "### Known-String Simplest-Common-Key Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4f6259",
   "metadata": {},
   "source": [
    "To search for the scrambled XOR key, we can use dynamic programming: the idea being we want to use as few different chunks as possible: we want as much contiguity as possible.  \n",
    "So for each starting position in the target strings, `ic`, we want to search between `start` to `end` for the longest contiguous XOR key which will decode all of the `targetString`s.\n",
    "When we have such a valid substring of the XOR key, it is the best candidate to decode up to its end if it can be used in a sequence such that on average as few different chunks are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840d65c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = min(map(len,targetStrings))\n",
    "\n",
    "nkeys = [-1]*(length+1)\n",
    "solkeys = [[]]*(length+1) # Note that a more efficient method of recovering the final solution is possible\n",
    "solkeylens = [[]]*(length+1)\n",
    "\n",
    "for ic in range(length):\n",
    "    for istart in range(start,end):\n",
    "        for ik in range(length-ic):\n",
    "            if any(debugme[tstart+ic+ik] ^ debugme[istart+ik] != ord(targetString[ic+ik]) for tstart,targetString in zip(targetStarts,targetStrings)):\n",
    "                break\n",
    "            score = ik+1\n",
    "            if nkeys[ic+score] == -1 or nkeys[ic+score] > nkeys[ic]+1:\n",
    "                nkeys[ic+score] = nkeys[ic] + 1\n",
    "                solkeys[ic+score] = solkeys[ic] + [istart]\n",
    "                solkeylens[ic+score] = solkeylens[ic] + [score]\n",
    "\n",
    "key_chunk_addrs = solkeys[-1]\n",
    "key_chunk_lens = solkeylens[-1]\n",
    "\n",
    "for kstart, klen in zip(key_chunk_addrs,key_chunk_lens):\n",
    "    print(f\"{hex(kstart+offset)}, {klen}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e4243f",
   "metadata": {},
   "source": [
    "Interestingly, we only 2 long chunks of length 12 and 15, and others all length 1. Also I don't see any pattern between the addresses of the longer chunks. Oh well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb340f32",
   "metadata": {},
   "source": [
    "### Simple Key Recovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771a3fbe",
   "metadata": {},
   "source": [
    "Of course the easiest way to get the key is to just take our longest known string and its start, which we now know, and XOR them to get out the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c50f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxStart = 0\n",
    "maxStr = ''\n",
    "for tstart,targetString in zip(targetStarts,targetStrings):\n",
    "    if len(targetString) > len(maxStr):\n",
    "        maxStart = tstart\n",
    "        maxStr = targetString\n",
    "\n",
    "xorkey = [debugme[maxStart+ik]^ord(c) for ik,c in enumerate(maxStr)]\n",
    "print(len(xorkey))\n",
    "print(xorkey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecb313c",
   "metadata": {},
   "source": [
    "### Unknown String Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b65d23d",
   "metadata": {},
   "source": [
    "With the key now in hand we can search for other unknown strings hidden in the binary. Im also going to check for when we reach a null byte, i.e. terminator for C strings, and then only check for padding null bytes afterwards. This way we can better see which strings are adjacent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 8\n",
    "for istart in range(start,end):\n",
    "    decoded = ''\n",
    "    nullhit = False\n",
    "    for ik,k in enumerate(xorkey):\n",
    "        c = debugme[istart+ik] ^ k\n",
    "        if c not in validset or (nullhit and c != 0):\n",
    "            break\n",
    "        nullhit = nullhit or c == 0\n",
    "        decoded += chr(c)\n",
    "    score = len(decoded)\n",
    "    if score >= threshold:\n",
    "        print(f\"{hex(istart+offset)}-{hex(istart+score+offset)}: {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34b9493",
   "metadata": {},
   "source": [
    "Amazing! Looks like we found the flag... or at least its printf template."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6d830a",
   "metadata": {},
   "source": [
    "### Guessing More Of The Key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9630f9",
   "metadata": {},
   "source": [
    "We have some of pieces of text which are cut off, but if we look through our original pairwise-XOR search, we can guess what they are and get more of the key.  \n",
    "Also I noticed is that the addresses almost always end in `0x0`, except for the 2 longest strings: this implies the strings are stored in blocks of 16 with null byte padding. We can use this to pull out the final few bytes of the XOR key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf688ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = 0x55c2b0 - offset\n",
    "targetString = \"Are you trying to influence me? Your Jedi mind tricks are no good here.\"\n",
    "remainder = 16 - (len(targetString) % 16)\n",
    "xorkey = [debugme[tstart+ik] ^ ord(c) for ik,c in enumerate(targetString)]\n",
    "xorkey = xorkey + [debugme[tstart+len(targetString)+ik] for ik in range(remainder)]\n",
    "print(len(xorkey))\n",
    "print(xorkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045439d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 8\n",
    "for istart in range(start,end):\n",
    "    decoded = ''\n",
    "    nullhit = False\n",
    "    for ik,k in enumerate(xorkey):\n",
    "        c = debugme[istart+ik] ^ k\n",
    "        if c not in validset or (nullhit and c != 0):\n",
    "            break\n",
    "        nullhit = nullhit or c == 0\n",
    "        decoded += chr(c)\n",
    "    score = len(decoded)\n",
    "    if score >= threshold:\n",
    "        print(f\"{hex(istart+offset)}-{hex(istart+score+offset)}: {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477e6fc4",
   "metadata": {},
   "source": [
    "## Patching The Binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362f6c47",
   "metadata": {},
   "source": [
    "### Marking The Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc58467",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('debugme_unpacked', 'rb') as f:\n",
    "    data = bytearray(f.read())\n",
    "\n",
    "xorkey_0 = 23 # xorkey[0] # The first byte of the XOR key\n",
    "offset = 0x400000\n",
    "addrs = [\n",
    "    (0x0055c008, 0x55c210), # \"I'm thinking...\"\n",
    "    (0x0055c038, 0x55c240), # \"Guess...\"\n",
    "    (0x0055c060, 0x55c270), # \"I don't...\"\n",
    "    (0x0055c0f8, 0x55c440), # \"Nope...\"\n",
    "]\n",
    "\n",
    "for debug,xorvl in addrs:\n",
    "    data[debug-offset] = ord('0')\n",
    "    data[xorvl-offset] = ord('1') ^ xorkey_0\n",
    "\n",
    "with open('debugme_marked', 'wb') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105c9450",
   "metadata": {},
   "source": [
    "### Disabling The TracerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d4d03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('debugme_marked', 'rb') as f:\n",
    "    data = bytearray(f.read())\n",
    "\n",
    "xorkey_0 = 23 # xorkey[0] # The first byte of the XOR key\n",
    "offset = 0x400000\n",
    "\n",
    "data[0x55c1e0-offset] = ord('_') ^ xorkey_0\n",
    "\n",
    "with open('debugme_notracerid', 'wb') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fa0993",
   "metadata": {},
   "source": [
    "### Disabling ptrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d952b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('debugme_notracerid', 'rb') as f:\n",
    "    data = bytearray(f.read())\n",
    "\n",
    "addr = 0x0051b72c\n",
    "offset = 0x400000\n",
    "\n",
    "data[addr-offset:addr-offset+2] = [0x90,0x90]\n",
    "\n",
    "with open('debugme_noptrace', 'wb') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff37a109",
   "metadata": {},
   "source": [
    "### Guaranteed Win "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed67829",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('debugme_noptrace', 'rb') as f:\n",
    "    data = bytearray(f.read())\n",
    "\n",
    "start_addr = 0x00404aa6\n",
    "end_addr = 0x00404ad8\n",
    "offset = 0x400000\n",
    "\n",
    "new_instr = [\n",
    "    0x4c, 0x89, 0xe9,\n",
    "    0x48, 0x33, 0x0d, 0xb8, 0x88, 0x1b, 0x00\n",
    "]\n",
    "\n",
    "l = end_addr-start_addr\n",
    "data[start_addr-offset:start_addr-offset+l] = new_instr + [0x90]*(l - len(new_instr))\n",
    "\n",
    "with open('debugme_solution', 'wb') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082a47a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
